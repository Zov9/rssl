{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lipeng/anaconda3/envs/torch1.12/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_p: tensor([0.1000, 0.7000, 0.4000, 0.9500])\n",
      "p_hat: tensor([0, 2, 1, 3])\n",
      "Selected thresholds: tensor([0.5000, 0.9000, 0.6000, 0.8000])\n",
      "select_mask: tensor([False, False, False,  True])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Example tensor of maximum probabilities\n",
    "max_p = torch.tensor([0.1, 0.7, 0.4, 0.95])\n",
    "\n",
    "# Example tensor of indices from torch.max (p_hat)\n",
    "p_hat = torch.tensor([0, 2, 1, 3])\n",
    "\n",
    "# Custom thresholds for each index that p_hat can take\n",
    "thresholds = torch.tensor([0.5, 0.6, 0.9, 0.8])\n",
    "\n",
    "# Gather the corresponding thresholds for each index in p_hat\n",
    "selected_thresholds = thresholds[p_hat]\n",
    "\n",
    "# Calculate the select_mask by comparing max_p with the selected thresholds\n",
    "select_mask = max_p.ge(selected_thresholds)\n",
    "\n",
    "print(f\"max_p: {max_p}\")\n",
    "print(f\"p_hat: {p_hat}\")\n",
    "print(f\"Selected thresholds: {selected_thresholds}\")\n",
    "print(f\"select_mask: {select_mask}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9500, 0.9500, 0.9500, 0.9500, 0.9500, 0.9500, 0.9500, 0.9500, 0.9500,\n",
      "        0.9500])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.full((10,), 0.95)\n",
    "\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor[2] = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9500, 0.9500, 0.2000, 0.9500, 0.9500, 0.9500, 0.9500, 0.9500, 0.9500,\n",
       "        0.9500])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified\n"
     ]
    }
   ],
   "source": [
    "class MyClass:\n",
    "    def __init__(self, value):\n",
    "        self.instance_variable = value\n",
    "\n",
    "def modify_object(obj):\n",
    "    obj.instance_variable = \"Modified\"\n",
    "\n",
    "# Create an instance of MyClass\n",
    "a = MyClass(\"Original\")\n",
    "\n",
    "# Pass the object to the function\n",
    "modify_object(a)\n",
    "\n",
    "# The instance variable of 'a' has been modified by the function\n",
    "print(a.instance_variable)  # Output: Modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_object(obj):\n",
    "    obj.instance_variable = \"hhh\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "modify_object(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hhh'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.instance_variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getrcps(filename):\n",
    "    #filename = '/data/lipeng/ABC/txt/cf100_0602t1.txt'\n",
    "    rc = []\n",
    "    ps = []\n",
    "    with open(filename, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        i = 0\n",
    "        while i < len(lines):\n",
    "                if lines[i].startswith('Class-wise Metrics (Recall and Precision)'):\n",
    "                    # Process the next 100 lines to get class index and recall value for the current epoch\n",
    "                    epoch_info = []\n",
    "                    recalls = []\n",
    "                    precisions = []\n",
    "                    for j in range(i + 1, i + 101):\n",
    "                        \n",
    "                        recall, precision = lines[j].split('Recall: ')[1].split(' Precision: ')[0], lines[j].split('Precision: ')[1]\n",
    "                        recalls.append(recall)\n",
    "                        precisions.append(precision)\n",
    "                        #print('class_line',class_line)\n",
    "                    \n",
    "                    assert len(recalls) == 100\n",
    "                    assert len(precisions) == 100\n",
    "                        \n",
    "                    rc.append(recalls)\n",
    "                    ps.append(precisions)\n",
    "                    \n",
    "                    #recall_smallest_20.append(sorted_indexes[:20])\n",
    "                    i += 100  # Move to the next epoch\n",
    "                else:\n",
    "                    i += 1\n",
    "    return rc,ps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = '/data/lipeng/ABC/txt/cf100_0602t1.txt'\n",
    "f2 = '/data/lipeng/ABC/txt/cf100_0602t2.txt'\n",
    "f3 = '/data/lipeng/ABC/txt/cf100_0602t3.txt'\n",
    "f4 = '/data/lipeng/ABC/txt/cf100_0602t4.txt'\n",
    "f5 = '/data/lipeng/ABC/txt/cf100_0602t5.txt'\n",
    "f6 = '/data/lipeng/ABC/txt/cf100_0602t6.txt'\n",
    "f7 = '/data/lipeng/ABC/txt/cf100_0602t7.txt'\n",
    "f8 = '/data/lipeng/ABC/txt/cf100_0602t8.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "rc1,ps1 = getrcps(f1)\n",
    "rc2,ps2 = getrcps(f2)\n",
    "rc3,ps3 = getrcps(f3)\n",
    "rc4,ps4 = getrcps(f4)\n",
    "rc5,ps5 = getrcps(f5)\n",
    "rc6,ps6 = getrcps(f6)\n",
    "rc7,ps7 = getrcps(f7)\n",
    "rc8,ps8 = getrcps(f8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = rc1[-5:]\n",
    "l2 = rc2[-5:]\n",
    "l3 = rc3[-5:]\n",
    "l4 = rc4[-5:]\n",
    "l5 = rc5[-5:]\n",
    "l6 = rc6[-5:]\n",
    "l7 = rc7[-5:]\n",
    "l8 = rc8[-5:]\n",
    "\n",
    "l1 = [[float(element) for element in sublist] for sublist in l1]\n",
    "l2 = [[float(element) for element in sublist] for sublist in l2]\n",
    "l3 = [[float(element) for element in sublist] for sublist in l3]\n",
    "l4 = [[float(element) for element in sublist] for sublist in l4]\n",
    "l5 = [[float(element) for element in sublist] for sublist in l5]\n",
    "l6 = [[float(element) for element in sublist] for sublist in l6]\n",
    "l7 = [[float(element) for element in sublist] for sublist in l7]\n",
    "l8 = [[float(element) for element in sublist] for sublist in l8]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = [sum(column) for column in zip(*l1)]\n",
    "m1 = [sum_value / len(l1) for sum_value in s1]\n",
    "\n",
    "s2 = [sum(column) for column in zip(*l2)]\n",
    "m2 = [sum_value / len(l2) for sum_value in s2]\n",
    "\n",
    "s3 = [sum(column) for column in zip(*l3)]\n",
    "m3 = [sum_value / len(l3) for sum_value in s3]\n",
    "\n",
    "s4 = [sum(column) for column in zip(*l4)]\n",
    "m4 = [sum_value / len(l4) for sum_value in s4]\n",
    "\n",
    "s5 = [sum(column) for column in zip(*l5)]\n",
    "m5 = [sum_value / len(l5) for sum_value in s5]\n",
    "\n",
    "s6 = [sum(column) for column in zip(*l6)]\n",
    "m6 = [sum_value / len(l6) for sum_value in s6]\n",
    "\n",
    "s7 = [sum(column) for column in zip(*l7)]\n",
    "m7 = [sum_value / len(l7) for sum_value in s7]\n",
    "\n",
    "s8 = [sum(column) for column in zip(*l8)]\n",
    "m8 = [sum_value / len(l8) for sum_value in s8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rete(data):\n",
    "    indexed_values = list(enumerate(data))\n",
    "\n",
    "    # Sort the pairs by value\n",
    "    sorted_indexed_values = sorted(indexed_values, key=lambda x: x[1])\n",
    "\n",
    "    # Extract the sorted indices\n",
    "    sorted_indices = [(index,round(value,3)) for index, value in sorted_indexed_values]\n",
    "    return sorted_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm1 = rete(m1)\n",
    "sm2 = rete(m2)\n",
    "sm3 = rete(m3)\n",
    "sm4 = rete(m4)\n",
    "sm5 = rete(m5)\n",
    "sm6 = rete(m6)\n",
    "sm7 = rete(m7)\n",
    "sm8 = rete(m8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(80, 0.074), (98, 0.098), (92, 0.13), (72, 0.134), (55, 0.176), (64, 0.198), (93, 0.2), (83, 0.21), (65, 0.22), (74, 0.226)]\n",
      "[(80, 0.072), (98, 0.122), (72, 0.13), (92, 0.13), (93, 0.188), (64, 0.228), (83, 0.23), (55, 0.248), (65, 0.258), (73, 0.26)]\n",
      "[(98, 0.054), (92, 0.076), (80, 0.106), (72, 0.128), (55, 0.212), (93, 0.218), (74, 0.222), (64, 0.23), (65, 0.236), (83, 0.25)]\n",
      "[(98, 0.054), (80, 0.142), (92, 0.168), (72, 0.186), (93, 0.208), (65, 0.214), (55, 0.222), (50, 0.29), (64, 0.298), (73, 0.306)]\n",
      "[(92, 0.102), (98, 0.126), (72, 0.128), (80, 0.152), (55, 0.192), (64, 0.228), (93, 0.228), (65, 0.242), (73, 0.278), (50, 0.3)]\n",
      "[(98, 0.072), (92, 0.122), (80, 0.138), (72, 0.146), (74, 0.194), (55, 0.202), (93, 0.208), (64, 0.262), (84, 0.28), (83, 0.29)]\n",
      "[(98, 0.084), (92, 0.112), (80, 0.126), (72, 0.206), (55, 0.224), (93, 0.252), (64, 0.284), (84, 0.302), (50, 0.316), (74, 0.322)]\n",
      "[(98, 0.134), (80, 0.146), (72, 0.154), (92, 0.19), (64, 0.202), (55, 0.22), (65, 0.222), (93, 0.232), (74, 0.248), (83, 0.306)]\n"
     ]
    }
   ],
   "source": [
    "print(sm1[:10])\n",
    "print(sm2[:10])\n",
    "print(sm3[:10])\n",
    "print(sm4[:10])\n",
    "print(sm5[:10])\n",
    "print(sm6[:10])\n",
    "print(sm7[:10])\n",
    "print(sm8[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = [[float(element) for element in sublist] for sublist in l1]\n",
    "l2 = [[float(element) for element in sublist] for sublist in l2]\n",
    "l3 = [[float(element) for element in sublist] for sublist in l3]\n",
    "l4 = [[float(element) for element in sublist] for sublist in l4]\n",
    "l5 = [[float(element) for element in sublist] for sublist in l5]\n",
    "l6 = [[float(element) for element in sublist] for sublist in l6]\n",
    "l7 = [[float(element) for element in sublist] for sublist in l7]\n",
    "l8 = [[float(element) for element in sublist] for sublist in l8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.91,\n",
       "  0.84,\n",
       "  0.6,\n",
       "  0.55,\n",
       "  0.64,\n",
       "  0.88,\n",
       "  0.81,\n",
       "  0.66,\n",
       "  0.9,\n",
       "  0.87,\n",
       "  0.5,\n",
       "  0.49,\n",
       "  0.82,\n",
       "  0.67,\n",
       "  0.66,\n",
       "  0.79,\n",
       "  0.71,\n",
       "  0.87,\n",
       "  0.57,\n",
       "  0.54,\n",
       "  0.9,\n",
       "  0.84,\n",
       "  0.76,\n",
       "  0.82,\n",
       "  0.77,\n",
       "  0.47,\n",
       "  0.55,\n",
       "  0.67,\n",
       "  0.8,\n",
       "  0.66,\n",
       "  0.68,\n",
       "  0.64,\n",
       "  0.71,\n",
       "  0.67,\n",
       "  0.72,\n",
       "  0.44,\n",
       "  0.72,\n",
       "  0.7,\n",
       "  0.58,\n",
       "  0.87,\n",
       "  0.42,\n",
       "  0.86,\n",
       "  0.75,\n",
       "  0.74,\n",
       "  0.32,\n",
       "  0.39,\n",
       "  0.31,\n",
       "  0.62,\n",
       "  0.86,\n",
       "  0.89,\n",
       "  0.29,\n",
       "  0.59,\n",
       "  0.75,\n",
       "  0.83,\n",
       "  0.77,\n",
       "  0.19,\n",
       "  0.86,\n",
       "  0.56,\n",
       "  0.8,\n",
       "  0.39,\n",
       "  0.81,\n",
       "  0.52,\n",
       "  0.59,\n",
       "  0.57,\n",
       "  0.2,\n",
       "  0.22,\n",
       "  0.53,\n",
       "  0.35,\n",
       "  0.9,\n",
       "  0.74,\n",
       "  0.64,\n",
       "  0.62,\n",
       "  0.14,\n",
       "  0.29,\n",
       "  0.21,\n",
       "  0.7,\n",
       "  0.8,\n",
       "  0.36,\n",
       "  0.36,\n",
       "  0.61,\n",
       "  0.09,\n",
       "  0.49,\n",
       "  0.82,\n",
       "  0.23,\n",
       "  0.31,\n",
       "  0.6,\n",
       "  0.5,\n",
       "  0.4,\n",
       "  0.55,\n",
       "  0.44,\n",
       "  0.37,\n",
       "  0.65,\n",
       "  0.14,\n",
       "  0.18,\n",
       "  0.89,\n",
       "  0.49,\n",
       "  0.37,\n",
       "  0.41,\n",
       "  0.08,\n",
       "  0.44],\n",
       " [0.92,\n",
       "  0.84,\n",
       "  0.62,\n",
       "  0.54,\n",
       "  0.6,\n",
       "  0.87,\n",
       "  0.83,\n",
       "  0.71,\n",
       "  0.88,\n",
       "  0.87,\n",
       "  0.45,\n",
       "  0.51,\n",
       "  0.8,\n",
       "  0.63,\n",
       "  0.65,\n",
       "  0.79,\n",
       "  0.73,\n",
       "  0.88,\n",
       "  0.58,\n",
       "  0.6,\n",
       "  0.9,\n",
       "  0.84,\n",
       "  0.73,\n",
       "  0.83,\n",
       "  0.77,\n",
       "  0.46,\n",
       "  0.54,\n",
       "  0.63,\n",
       "  0.78,\n",
       "  0.66,\n",
       "  0.7,\n",
       "  0.6,\n",
       "  0.73,\n",
       "  0.7,\n",
       "  0.7,\n",
       "  0.39,\n",
       "  0.72,\n",
       "  0.74,\n",
       "  0.59,\n",
       "  0.86,\n",
       "  0.41,\n",
       "  0.88,\n",
       "  0.74,\n",
       "  0.74,\n",
       "  0.3,\n",
       "  0.41,\n",
       "  0.33,\n",
       "  0.6,\n",
       "  0.86,\n",
       "  0.87,\n",
       "  0.32,\n",
       "  0.58,\n",
       "  0.77,\n",
       "  0.83,\n",
       "  0.77,\n",
       "  0.17,\n",
       "  0.86,\n",
       "  0.55,\n",
       "  0.81,\n",
       "  0.44,\n",
       "  0.79,\n",
       "  0.57,\n",
       "  0.61,\n",
       "  0.58,\n",
       "  0.19,\n",
       "  0.22,\n",
       "  0.55,\n",
       "  0.34,\n",
       "  0.91,\n",
       "  0.74,\n",
       "  0.61,\n",
       "  0.62,\n",
       "  0.13,\n",
       "  0.35,\n",
       "  0.23,\n",
       "  0.7,\n",
       "  0.78,\n",
       "  0.38,\n",
       "  0.33,\n",
       "  0.58,\n",
       "  0.07,\n",
       "  0.48,\n",
       "  0.83,\n",
       "  0.23,\n",
       "  0.33,\n",
       "  0.64,\n",
       "  0.48,\n",
       "  0.41,\n",
       "  0.51,\n",
       "  0.41,\n",
       "  0.4,\n",
       "  0.63,\n",
       "  0.14,\n",
       "  0.18,\n",
       "  0.89,\n",
       "  0.5,\n",
       "  0.34,\n",
       "  0.37,\n",
       "  0.09,\n",
       "  0.46],\n",
       " [0.9,\n",
       "  0.84,\n",
       "  0.6,\n",
       "  0.52,\n",
       "  0.61,\n",
       "  0.89,\n",
       "  0.82,\n",
       "  0.65,\n",
       "  0.89,\n",
       "  0.88,\n",
       "  0.54,\n",
       "  0.51,\n",
       "  0.81,\n",
       "  0.62,\n",
       "  0.65,\n",
       "  0.79,\n",
       "  0.73,\n",
       "  0.87,\n",
       "  0.55,\n",
       "  0.57,\n",
       "  0.88,\n",
       "  0.84,\n",
       "  0.73,\n",
       "  0.83,\n",
       "  0.8,\n",
       "  0.43,\n",
       "  0.55,\n",
       "  0.64,\n",
       "  0.79,\n",
       "  0.64,\n",
       "  0.69,\n",
       "  0.59,\n",
       "  0.71,\n",
       "  0.68,\n",
       "  0.72,\n",
       "  0.4,\n",
       "  0.72,\n",
       "  0.74,\n",
       "  0.52,\n",
       "  0.85,\n",
       "  0.41,\n",
       "  0.88,\n",
       "  0.71,\n",
       "  0.76,\n",
       "  0.3,\n",
       "  0.41,\n",
       "  0.39,\n",
       "  0.6,\n",
       "  0.87,\n",
       "  0.88,\n",
       "  0.29,\n",
       "  0.61,\n",
       "  0.75,\n",
       "  0.86,\n",
       "  0.78,\n",
       "  0.17,\n",
       "  0.85,\n",
       "  0.57,\n",
       "  0.8,\n",
       "  0.45,\n",
       "  0.83,\n",
       "  0.51,\n",
       "  0.65,\n",
       "  0.54,\n",
       "  0.19,\n",
       "  0.21,\n",
       "  0.54,\n",
       "  0.35,\n",
       "  0.91,\n",
       "  0.75,\n",
       "  0.62,\n",
       "  0.6,\n",
       "  0.11,\n",
       "  0.34,\n",
       "  0.22,\n",
       "  0.72,\n",
       "  0.78,\n",
       "  0.39,\n",
       "  0.37,\n",
       "  0.59,\n",
       "  0.08,\n",
       "  0.48,\n",
       "  0.82,\n",
       "  0.2,\n",
       "  0.32,\n",
       "  0.64,\n",
       "  0.54,\n",
       "  0.38,\n",
       "  0.54,\n",
       "  0.41,\n",
       "  0.39,\n",
       "  0.6,\n",
       "  0.12,\n",
       "  0.19,\n",
       "  0.91,\n",
       "  0.46,\n",
       "  0.35,\n",
       "  0.41,\n",
       "  0.1,\n",
       "  0.45],\n",
       " [0.92,\n",
       "  0.85,\n",
       "  0.65,\n",
       "  0.53,\n",
       "  0.59,\n",
       "  0.88,\n",
       "  0.82,\n",
       "  0.64,\n",
       "  0.92,\n",
       "  0.88,\n",
       "  0.52,\n",
       "  0.47,\n",
       "  0.81,\n",
       "  0.64,\n",
       "  0.65,\n",
       "  0.8,\n",
       "  0.72,\n",
       "  0.84,\n",
       "  0.56,\n",
       "  0.58,\n",
       "  0.88,\n",
       "  0.81,\n",
       "  0.7,\n",
       "  0.84,\n",
       "  0.8,\n",
       "  0.41,\n",
       "  0.57,\n",
       "  0.63,\n",
       "  0.78,\n",
       "  0.65,\n",
       "  0.69,\n",
       "  0.6,\n",
       "  0.67,\n",
       "  0.69,\n",
       "  0.69,\n",
       "  0.36,\n",
       "  0.7,\n",
       "  0.71,\n",
       "  0.54,\n",
       "  0.86,\n",
       "  0.41,\n",
       "  0.88,\n",
       "  0.72,\n",
       "  0.74,\n",
       "  0.32,\n",
       "  0.4,\n",
       "  0.35,\n",
       "  0.64,\n",
       "  0.87,\n",
       "  0.87,\n",
       "  0.32,\n",
       "  0.63,\n",
       "  0.7,\n",
       "  0.85,\n",
       "  0.8,\n",
       "  0.17,\n",
       "  0.84,\n",
       "  0.62,\n",
       "  0.82,\n",
       "  0.48,\n",
       "  0.82,\n",
       "  0.52,\n",
       "  0.65,\n",
       "  0.6,\n",
       "  0.22,\n",
       "  0.22,\n",
       "  0.55,\n",
       "  0.35,\n",
       "  0.9,\n",
       "  0.75,\n",
       "  0.6,\n",
       "  0.62,\n",
       "  0.14,\n",
       "  0.29,\n",
       "  0.24,\n",
       "  0.72,\n",
       "  0.79,\n",
       "  0.36,\n",
       "  0.37,\n",
       "  0.57,\n",
       "  0.08,\n",
       "  0.51,\n",
       "  0.82,\n",
       "  0.18,\n",
       "  0.34,\n",
       "  0.63,\n",
       "  0.51,\n",
       "  0.39,\n",
       "  0.54,\n",
       "  0.45,\n",
       "  0.35,\n",
       "  0.6,\n",
       "  0.14,\n",
       "  0.21,\n",
       "  0.91,\n",
       "  0.49,\n",
       "  0.34,\n",
       "  0.44,\n",
       "  0.11,\n",
       "  0.44],\n",
       " [0.92,\n",
       "  0.87,\n",
       "  0.59,\n",
       "  0.52,\n",
       "  0.62,\n",
       "  0.88,\n",
       "  0.85,\n",
       "  0.61,\n",
       "  0.88,\n",
       "  0.88,\n",
       "  0.5,\n",
       "  0.49,\n",
       "  0.83,\n",
       "  0.64,\n",
       "  0.69,\n",
       "  0.79,\n",
       "  0.72,\n",
       "  0.84,\n",
       "  0.53,\n",
       "  0.57,\n",
       "  0.89,\n",
       "  0.83,\n",
       "  0.7,\n",
       "  0.84,\n",
       "  0.79,\n",
       "  0.44,\n",
       "  0.58,\n",
       "  0.62,\n",
       "  0.8,\n",
       "  0.62,\n",
       "  0.66,\n",
       "  0.62,\n",
       "  0.66,\n",
       "  0.7,\n",
       "  0.73,\n",
       "  0.36,\n",
       "  0.71,\n",
       "  0.69,\n",
       "  0.52,\n",
       "  0.86,\n",
       "  0.41,\n",
       "  0.88,\n",
       "  0.71,\n",
       "  0.75,\n",
       "  0.32,\n",
       "  0.4,\n",
       "  0.35,\n",
       "  0.64,\n",
       "  0.88,\n",
       "  0.85,\n",
       "  0.31,\n",
       "  0.63,\n",
       "  0.74,\n",
       "  0.83,\n",
       "  0.77,\n",
       "  0.18,\n",
       "  0.84,\n",
       "  0.53,\n",
       "  0.8,\n",
       "  0.44,\n",
       "  0.84,\n",
       "  0.49,\n",
       "  0.63,\n",
       "  0.57,\n",
       "  0.19,\n",
       "  0.23,\n",
       "  0.54,\n",
       "  0.33,\n",
       "  0.9,\n",
       "  0.75,\n",
       "  0.6,\n",
       "  0.62,\n",
       "  0.15,\n",
       "  0.3,\n",
       "  0.23,\n",
       "  0.7,\n",
       "  0.77,\n",
       "  0.33,\n",
       "  0.35,\n",
       "  0.57,\n",
       "  0.05,\n",
       "  0.53,\n",
       "  0.82,\n",
       "  0.21,\n",
       "  0.38,\n",
       "  0.67,\n",
       "  0.46,\n",
       "  0.41,\n",
       "  0.56,\n",
       "  0.47,\n",
       "  0.34,\n",
       "  0.61,\n",
       "  0.11,\n",
       "  0.24,\n",
       "  0.91,\n",
       "  0.46,\n",
       "  0.34,\n",
       "  0.4,\n",
       "  0.11,\n",
       "  0.47]]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.44 0.46 0.45 0.44 0.47 0.45199999999999996\n"
     ]
    }
   ],
   "source": [
    "print(l1[0][-1],l1[1][-1],l1[2][-1],l1[3][-1],l1[4][-1],(l1[0][-1]+l1[1][-1]+l1[2][-1]+l1[3][-1]+l1[4][-1])/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sums = [sum(column) for column in zip(*l1)]\n",
    "\n",
    "# Calculate the mean of each dimension by dividing the sum by the number of elements\n",
    "means = [sum_value / len(l1) for sum_value in sums]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45199999999999996"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indices of the biggest values: [4 3 2]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Example array\n",
    "overlap_avg_upart = np.array([10, 20, 30, 40, 50])\n",
    "\n",
    "# Sorting and getting indices of the biggest values\n",
    "asc_indices2 = np.argsort(overlap_avg_upart)\n",
    "desc_indices2 = asc_indices2[::-1]\n",
    "ret = desc_indices2[:3]\n",
    "\n",
    "print('Indices of the biggest values:', ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean using statistics.mean(): 4.666666666666667\n",
      "Mean using torch.mean(): 4.666666507720947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lipeng/anaconda3/envs/torch1.12/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "import torch\n",
    "\n",
    "dict_from_pairs = {\n",
    "    'item1': torch.tensor(1.0),\n",
    "    'item2': torch.tensor(5.0),\n",
    "    'item3': torch.tensor(8.0)\n",
    "}\n",
    "\n",
    "# Convert tensor values to a list of numbers for statistics.mean()\n",
    "mean_stats = statistics.mean([float(value) for value in dict_from_pairs.values()])\n",
    "print('Mean using statistics.mean():', mean_stats)\n",
    "\n",
    "# Calculate the mean using torch.mean()\n",
    "mean_torch = torch.mean(torch.stack(list(dict_from_pairs.values())), dim=0)\n",
    "print('Mean using torch.mean():', mean_torch.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SupConLoss3(nn.Module):  #supconloss3对所有样本都有closs但对w类额外加一项  实际上是w类一项 + 非w类一项\n",
    "\n",
    "    def __init__(self, temperature=0.5,distance=0.5, scale_by_temperature=True):\n",
    "        super(SupConLoss3, self).__init__()\n",
    "        self.temperature = temperature\n",
    "        self.distance = distance\n",
    "        self.scale_by_temperature = scale_by_temperature\n",
    "\n",
    "    def forward(self, tmask,worstk,features1, features2,labels1 = None ,labels2 = None, mask=None):# x, u, labelx, labelu\n",
    "       \n",
    "        device = (torch.device('cuda'))\n",
    "        print('features1\\n',features1)\n",
    "        print('features2\\n',features2)\n",
    "        features1 = F.normalize(features1, p=2, dim=1)\n",
    "        features2 = F.normalize(features2, p=2, dim=1)\n",
    "        print('features1\\n',features1)\n",
    "        print('features2\\n',features2)\n",
    "        batch_size = features1.shape[0]\n",
    "        batch_size2 = features2.shape[0]\n",
    "        # 关于labels参数\n",
    "        #if labels is not None and mask is not None:  # labels和mask不能同时定义值，因为如果有label，那么mask是需要根据Label得到的\n",
    "        #    raise ValueError('Cannot define both `labels` and `mask`') \n",
    "        #print('labels1[0]',labels1[0])\n",
    "        num_class = len(labels1[0])\n",
    "        labels1 = torch.argmax(labels1, dim=1)\n",
    "        \n",
    "        #print('labels1[0]',labels1[0])\n",
    "        labels1 = labels1.contiguous().view(-1, 1)\n",
    "        #labels2 = torch.argmax(labels2, dim=1)\n",
    "        labels2 = labels2.contiguous().view(-1, 1)\n",
    "\n",
    "        print('labels1\\n',labels1)\n",
    "        print('labels2\\n',labels2)\n",
    "        #print('label1 shape0:',labels1.shape[0],'label2 shape0:',labels2.shape[0],'feature1 shape0:',features1.shape[0],'feature2 shape0:',features2.shape[0])\n",
    "        if labels1.shape[0] != batch_size:\n",
    "            raise ValueError('Num of labels does not match num of features')\n",
    "        mask = torch.eq(labels1, labels2.T).float().to(device)\n",
    "        mask2 = torch.eq(labels2, labels2.T).float().to(device)\n",
    "        #mask3  based on worstk\n",
    "        mask3 = torch.zeros(batch_size)\n",
    "        #mask4  1 for mask and 0 for mask3, designed for samples not in worstk classes\n",
    "        mask4 = torch.zeros(batch_size)\n",
    "        for i in range(batch_size):\n",
    "            #print('labels2[i]',labels2[i],'worstk',worstk)\n",
    "            if labels2[i] in worstk:\n",
    "                mask3[i] = 1\n",
    "        mask3 = mask3.to(device)  \n",
    "             \n",
    "        mask4 = 1.-mask3\n",
    "        \n",
    "        mask4 = mask4.to(device)\n",
    "        print('mask\\n',mask)\n",
    "        print('mask2\\n',mask2)\n",
    "        print('mask3\\n',mask3)\n",
    "        print('mask4\\n',mask4)\n",
    "        #40print('mask3',mask3)\n",
    "        # compute logits\n",
    "        anchor_dot_contrast1 = torch.div(                \n",
    "            torch.matmul(features1, features2.T),\n",
    "            self.temperature)  # Lx * Lu\n",
    "        anchor_dot_contrast2 = torch.div(\n",
    "            torch.matmul(features2, features2.T),\n",
    "            self.temperature)  # Lu * Lu\n",
    "        anchor_dot_contrast3 = torch.div(\n",
    "            torch.matmul(features2, features2.T)+self.distance,   #0.5 是distance, 可以考虑成类间距离或者类和最远样本的距离\n",
    "            self.temperature)  # Lu * Lu\n",
    "        \n",
    "        print('anchor_dot_contrast1\\n',anchor_dot_contrast1)\n",
    "        print('anchor_dot_contrast2\\n',anchor_dot_contrast2)\n",
    "        print('anchor_dot_contrast3\\n',anchor_dot_contrast3)\n",
    "\n",
    "        # for numerical stability\n",
    "        logits_max1, _ = torch.max(anchor_dot_contrast1, dim=1, keepdim=True)\n",
    "        logits_max2, _ = torch.max(anchor_dot_contrast2, dim=1, keepdim=True)\n",
    "        logits_max3, _ = torch.max(anchor_dot_contrast3, dim=1, keepdim=True)\n",
    "        logits1 = anchor_dot_contrast1 - logits_max1.detach()\n",
    "        logits2 = anchor_dot_contrast2 - logits_max2.detach()\n",
    "        #logits3 = anchor_dot_contrast3 - logits_max3.detach()\n",
    "        logits3 = anchor_dot_contrast3 - logits_max2.detach()  #上下两行到底用哪个 可以都试试\n",
    "        exp_logits1 = torch.exp(logits1)\n",
    "        exp_logits2 = torch.exp(logits2)\n",
    "        exp_logits3 = torch.exp(logits3)\n",
    "\n",
    "        print('exp_logits1\\n',exp_logits1)\n",
    "        print('exp_logits2\\n',exp_logits2)\n",
    "        print('exp_logits3\\n',exp_logits3)\n",
    "      \n",
    "        # 构建mask \n",
    "        #logits_mask = torch.ones_like(mask) - torch.eye(batch_size)     \n",
    "        logits_mask1 = torch.ones_like(mask).to(device)                          #label and unlabel\n",
    "        \n",
    "\n",
    "        logits_mask2 = torch.ones_like(mask2).to(device) - torch.eye(batch_size2).to(device)  #unlabel and unlabel\n",
    "\n",
    "        positives_mask1 = mask * logits_mask1\n",
    "        negatives_mask1 = 1. - mask                 #? 这里是不是有问题？ 是 1-mask 还是 1-positive mask? \n",
    "        #??????????????????????????????????????????????????????????????????????????????????????????????\n",
    "        positives_mask2 = mask2 * logits_mask2\n",
    "        negatives_mask2 = 1. - mask2\n",
    "          \n",
    "        num_positives_per_row  = torch.sum(positives_mask1 , axis=1) # 除了自己之外，正样本的个数  [2 0 2 2]    \n",
    "        num_positives_per_row_selected = mask3 * num_positives_per_row.t() \n",
    "        num_positives_per_row_unselected = mask4 * num_positives_per_row.t() \n",
    "\n",
    "        num_positives_per_row2  = torch.sum(positives_mask2 , axis=1) # 除了自己之外，正样本的个数  [2 0 2 2]    \n",
    "        num_positives_per_row_selected2 = mask3 * num_positives_per_row.t() \n",
    "        num_positives_per_row_unselected2 = mask4 * num_positives_per_row.t() \n",
    "\n",
    "        print('logits_mask1\\n',logits_mask1)\n",
    "        print('logits_mask2\\n',logits_mask2)\n",
    "        print('positives_mask1\\n',positives_mask1)\n",
    "        print('negatives_mask1\\n',negatives_mask1)\n",
    "        print('positives_mask2\\n',positives_mask2)\n",
    "        print('negatives_mask2\\n',negatives_mask2)\n",
    "        print('num_positives_per_row\\n',num_positives_per_row)\n",
    "        print('num_positives_per_row_selected\\n',num_positives_per_row_selected)\n",
    "        print('num_positives_per_row_unselected\\n',num_positives_per_row_unselected)\n",
    "\n",
    "        #print('Number of elements greater than 0 for original selection:',(num_positives_per_row > 0).sum().item())\n",
    "        #print('Number of elements greater than 0 for  my  selection:',(num_positives_per_row_selected > 0).sum().item())\n",
    "        \n",
    "        denominator = torch.sum(\n",
    "        exp_logits2 * negatives_mask2, axis=1, keepdims=True) + torch.sum(\n",
    "            exp_logits2 * positives_mask2, axis=1, keepdims=True)  \n",
    "        \n",
    "        denominator1 = torch.sum(\n",
    "        exp_logits3 * negatives_mask2, axis=1, keepdims=True) + torch.sum(\n",
    "            exp_logits3 * positives_mask2, axis=1, keepdims=True)  \n",
    "        \n",
    "        log_probs = logits1 - torch.log(denominator)\n",
    "        if torch.any(torch.isnan(log_probs)):\n",
    "            raise ValueError(\"Log_prob has nan!\")\n",
    "        \n",
    "        log_probs1 = logits1 - torch.log(denominator1)\n",
    "        if torch.any(torch.isnan(log_probs)):\n",
    "            raise ValueError(\"Log_prob has nan!\")\n",
    "        print('shape!!!!!!!!!!!!!!!!!!')\n",
    "        print(logits1.shape)\n",
    "        print(denominator.shape)\n",
    "        print(log_probs.shape)\n",
    "        print('denominator\\n',denominator)\n",
    "        print('denominator1\\n',denominator1)\n",
    "        print('log_probs\\n',log_probs)\n",
    "        print('log_probs1\\n',log_probs1)\n",
    "\n",
    "        #log_probs = torch.sum(\n",
    "        #    log_probs*positives_mask1 , axis=1)[num_positives_per_row > 0] / num_positives_per_row[num_positives_per_row > 0]\n",
    "        log_probs = torch.sum(\n",
    "            log_probs*positives_mask1 , axis=1)[num_positives_per_row_selected > 0] / num_positives_per_row_selected[num_positives_per_row_selected > 0]\n",
    "        \n",
    "        log_probs1 = torch.sum(\n",
    "            log_probs1*positives_mask1 , axis=1)[num_positives_per_row_unselected > 0] / num_positives_per_row_unselected[num_positives_per_row_unselected > 0]\n",
    "        \n",
    "        print('log_probs_\\n',log_probs)\n",
    "        print('log_probs1_\\n',log_probs1)\n",
    "        # loss\n",
    "        loss = -log_probs\n",
    "        loss1 = -log_probs1\n",
    "        print('loss\\n',loss)\n",
    "        print('loss1\\n',loss1)\n",
    "        #if self.scale_by_temperature:\n",
    "        #    loss *= self.temperature\n",
    "        loss = loss.mean()\n",
    "        loss1 = loss1.mean()\n",
    "        print('loss\\n',loss)\n",
    "        print('loss1\\n',loss1)\n",
    "        return loss+loss1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features1\n",
      " tensor([[-1.3319e+00, -2.9859e-01,  1.3565e+00, -2.2746e-02,  1.0880e+00],\n",
      "        [ 9.7534e-01, -1.2635e+00, -2.1612e+00,  8.4856e-01, -6.1491e-01],\n",
      "        [ 3.0849e-01,  1.1111e+00, -8.9221e-02,  3.7861e-01, -4.7281e-01],\n",
      "        [ 1.7549e+00, -6.0274e-01, -3.9193e-01, -1.8942e-01, -7.0016e-02],\n",
      "        [-1.3926e+00, -5.4271e-02,  1.0732e+00,  1.8287e+00, -9.0819e-01],\n",
      "        [-4.7142e-01,  1.5794e+00, -6.0579e-01,  3.4573e-01,  2.3442e-01],\n",
      "        [-8.2301e-01, -3.6539e-01, -6.0663e-01, -9.3901e-01, -5.5511e-01],\n",
      "        [-5.4449e-01, -4.4430e-01,  4.7565e-02, -7.8211e-01, -9.9691e-01],\n",
      "        [-6.2123e-01, -1.3961e-01,  7.2223e-01, -6.3786e-01, -1.2132e+00],\n",
      "        [ 5.4021e-01, -1.1646e+00,  5.0959e-01, -1.1803e+00, -8.0963e-01],\n",
      "        [-6.6417e-01, -6.1459e-01, -6.2437e-01,  2.5477e-01, -1.2060e-01],\n",
      "        [-9.4313e-01,  1.4213e-01,  7.0065e-01, -8.4266e-01,  8.6579e-01],\n",
      "        [ 1.1423e+00, -1.3140e+00,  2.0399e+00,  3.5004e-01, -2.1559e+00],\n",
      "        [-5.8904e-01,  6.3634e-01,  4.3197e-01, -1.2180e+00, -1.7361e+00],\n",
      "        [ 1.4968e+00,  3.3712e-01, -2.5162e-01, -8.7984e-01,  6.5388e-01],\n",
      "        [ 5.6930e-02,  1.4660e+00, -5.3342e-01, -8.1864e-01,  6.5433e-01],\n",
      "        [-1.5857e+00,  8.0667e-01, -4.6605e-01,  3.9481e-01, -1.1240e+00],\n",
      "        [-2.4153e+00, -3.8549e-01, -2.3240e-01,  5.0758e-01,  5.2426e-01],\n",
      "        [ 9.7907e-01, -5.8846e-01, -4.4110e-01,  1.0867e+00, -5.4427e-01],\n",
      "        [-3.8460e-01, -1.4137e+00, -2.1728e-01, -1.2044e+00, -1.4489e+00],\n",
      "        [ 1.6281e+00, -6.2415e-01,  6.8190e-01, -9.3785e-01,  2.4321e-01],\n",
      "        [-1.7591e-01, -1.4869e+00, -2.2096e+00, -5.1118e-01,  1.4168e+00],\n",
      "        [ 1.5955e+00, -2.2068e-01, -8.0291e-02,  1.3311e+00,  8.6417e-01],\n",
      "        [ 3.8381e-01,  5.3551e-01, -5.2957e-01, -2.3006e+00, -6.9643e-01],\n",
      "        [ 2.5001e+00,  1.3676e+00,  1.1541e+00,  4.3936e-01, -6.1404e-01],\n",
      "        [ 2.6485e-01,  2.1617e-01, -8.4003e-01, -6.2902e-01,  1.0903e+00],\n",
      "        [-7.0705e-01,  2.7187e-01, -5.1787e-01,  1.7129e-01, -3.2714e-01],\n",
      "        [ 1.8544e+00, -5.2244e-01, -2.2875e+00,  2.1097e+00, -1.2685e+00],\n",
      "        [-1.4016e+00,  1.1702e-01,  8.4416e-01,  7.9708e-01,  2.7220e-01],\n",
      "        [ 1.3642e+00,  7.6571e-01,  1.0037e-01,  5.5941e-01, -2.3992e-01],\n",
      "        [-9.8013e-01,  8.4336e-01, -2.7825e-01, -5.3204e-01, -1.0287e+00],\n",
      "        [ 6.3058e-01,  3.6454e-01,  6.1733e-01,  1.3317e-01, -1.5663e+00],\n",
      "        [ 9.3131e-01,  9.0560e-01, -3.9948e-01, -6.2283e-01,  9.3554e-01],\n",
      "        [-9.1215e-01,  1.4804e-03, -3.0419e-01,  6.0519e-01,  9.2018e-01],\n",
      "        [-1.7120e-01,  9.0669e-01, -1.4036e-01,  1.0067e-01,  6.5643e-01],\n",
      "        [-3.3749e-01, -1.0747e-01,  5.2294e-01, -2.7114e-01, -1.7394e+00],\n",
      "        [-9.9116e-01, -2.5350e-01,  9.7226e-01,  1.3002e+00, -1.0233e+00],\n",
      "        [ 1.1969e+00,  1.4072e+00, -2.6051e-01,  7.6588e-01,  1.3014e+00],\n",
      "        [-8.9615e-02,  1.3070e+00,  1.9882e+00,  2.2991e-01, -3.4131e-01],\n",
      "        [ 1.6283e-01,  1.5427e+00,  9.1164e-01,  7.9704e-01, -1.0325e+00],\n",
      "        [-5.5764e-01, -7.5977e-01,  1.5460e+00,  6.1239e-01,  5.3268e-01],\n",
      "        [ 4.3220e-01, -8.3048e-01,  9.3013e-01,  3.2171e-01,  8.0966e-01],\n",
      "        [-7.5033e-01,  5.9943e-02,  1.3450e+00,  1.9452e+00, -1.1241e+00],\n",
      "        [-1.5788e+00, -1.1118e+00,  1.7539e+00, -8.7468e-01,  5.1666e-01],\n",
      "        [-4.4086e-02, -3.5062e-01, -1.5615e+00,  5.1311e-01, -7.1435e-01],\n",
      "        [-8.0285e-01,  2.8486e-01,  1.6389e-01, -4.6892e-01, -8.2307e-01],\n",
      "        [-3.6577e-01,  1.9849e-02,  9.7346e-01, -1.7450e+00,  4.0171e-01],\n",
      "        [-4.6741e-01, -4.3271e-01,  4.9341e-01, -7.7546e-01,  2.1419e-02],\n",
      "        [ 7.6180e-02,  1.5455e+00,  1.7772e-01, -1.8048e-01,  9.6632e-01],\n",
      "        [-8.6079e-01,  1.6874e-01,  4.1588e-01, -1.1021e+00, -1.5199e+00],\n",
      "        [ 2.8085e-01,  2.3498e-01, -5.3019e-01,  3.7504e-01,  3.7804e-01],\n",
      "        [-1.7033e-02, -2.4382e-01,  3.0254e-01, -3.0389e-01, -3.1679e-01],\n",
      "        [ 2.1770e+00,  9.8651e-01,  1.6633e+00, -2.3860e-01,  1.0518e-01],\n",
      "        [ 2.4391e+00, -1.6277e+00,  6.9517e-01,  8.8067e-01, -9.4964e-02],\n",
      "        [ 1.9447e-01,  2.3063e+00,  1.7065e-01,  9.9478e-01,  7.3196e-01],\n",
      "        [ 9.8537e-01,  4.6649e-01,  2.2596e+00, -1.1398e+00,  7.7780e-03],\n",
      "        [ 4.3420e-01, -2.1433e+00, -2.1515e-01,  1.1709e+00,  6.5187e-02],\n",
      "        [ 6.9636e-01, -1.0020e+00,  1.0713e-01, -1.7001e+00, -8.7354e-01],\n",
      "        [-1.9075e+00, -1.8961e-01, -3.9725e-01,  7.4679e-01,  1.0613e+00],\n",
      "        [ 6.6757e-01, -5.5824e-01, -1.5673e+00, -1.6213e+00, -6.2281e-01],\n",
      "        [ 2.9715e-01,  7.9335e-01, -3.7618e-01,  4.9315e-01, -1.0290e+00],\n",
      "        [ 4.1340e-01,  1.0422e+00, -1.2399e+00, -1.9302e-01,  1.3768e+00],\n",
      "        [-6.7946e-01,  1.4439e+00,  3.2410e+00,  3.9345e-01, -1.2887e-01],\n",
      "        [ 1.1448e+00, -4.5095e-01,  1.4551e+00, -1.0651e+00, -5.8349e-01]],\n",
      "       device='cuda:0')\n",
      "features2\n",
      " tensor([[-1.5206e+00, -1.2360e+00, -1.0071e+00, -8.6461e-02, -2.3486e-01],\n",
      "        [-2.2291e+00,  7.0108e-01, -2.1939e+00,  7.3792e-01,  2.9901e+00],\n",
      "        [-1.6853e-01,  2.2334e+00,  1.1818e+00,  9.0258e-01, -4.0077e-01],\n",
      "        [ 1.7135e+00,  4.2646e-02, -3.9219e-01, -5.6070e-01, -1.0657e+00],\n",
      "        [ 1.6231e+00, -2.2693e-01,  6.7060e-01, -5.6753e-01,  4.5357e-01],\n",
      "        [ 7.1511e-01, -4.5776e-01,  9.5247e-02,  1.4245e+00, -4.8560e-01],\n",
      "        [-7.1628e-01, -1.3386e-02, -2.1129e+00, -1.8524e+00,  1.4346e+00],\n",
      "        [ 2.2122e-01, -1.3953e+00,  3.4327e-01,  1.3143e-01,  2.0620e+00],\n",
      "        [-1.3373e+00,  1.8904e+00, -7.3346e-01,  2.0744e-01,  1.2694e+00],\n",
      "        [ 1.2118e+00, -8.6575e-01, -1.7935e-01,  7.5988e-01,  1.5894e+00],\n",
      "        [-3.9518e-01,  1.1525e+00, -5.8403e-01,  6.0052e-01, -8.2746e-01],\n",
      "        [ 5.2869e-01,  1.2972e-01, -1.1522e+00, -2.6276e-01,  9.0082e-02],\n",
      "        [-5.9984e-01, -9.9981e-01,  1.0886e+00,  1.9085e+00,  7.8340e-01],\n",
      "        [ 9.9674e-01, -7.6868e-01,  1.1999e+00,  3.0630e-01, -3.2187e-01],\n",
      "        [ 3.3843e-01, -1.6554e+00, -6.3288e-01, -1.5712e-01, -1.1525e+00],\n",
      "        [ 9.5301e-01,  1.4653e-01,  1.6671e+00,  1.1904e+00, -2.0726e-01],\n",
      "        [-6.2958e-01, -7.1732e-01, -1.2131e+00, -3.0506e-01, -6.4126e-01],\n",
      "        [ 2.8749e-01, -1.3591e+00, -6.5614e-01, -6.4130e-01, -7.7561e-01],\n",
      "        [ 6.8478e-01, -1.5845e+00, -2.3452e+00,  2.5877e-01,  1.0820e+00],\n",
      "        [ 1.4616e+00, -1.6158e-01, -1.4933e+00,  2.0286e+00,  6.6843e-01],\n",
      "        [-4.2694e-01, -8.8763e-01, -5.0673e-01, -1.4165e+00, -6.5823e-01],\n",
      "        [-2.6064e-01,  9.9456e-01, -1.2224e+00,  7.8189e-01, -2.5459e-01],\n",
      "        [ 4.8102e-01, -1.0748e+00,  6.3018e-01, -1.3126e+00,  7.8079e-01],\n",
      "        [ 2.0125e+00,  5.5527e-02, -9.8494e-02, -5.4328e-01, -1.5385e+00],\n",
      "        [-1.0400e+00, -3.8053e-01,  1.1914e+00,  9.2740e-02, -3.7777e-01],\n",
      "        [ 1.8722e-01, -1.2643e+00,  8.4353e-01,  1.4137e+00,  9.4303e-01],\n",
      "        [-7.7783e-01, -2.9891e-01, -2.3470e+00, -7.0452e-01,  1.4632e+00],\n",
      "        [ 1.4038e+00,  1.4136e+00, -1.3060e+00,  3.2903e-01,  1.0677e+00],\n",
      "        [ 5.7565e-01, -3.3267e-01,  9.6108e-02,  2.2215e-02, -1.1326e+00],\n",
      "        [-9.4419e-01, -5.7241e-01,  6.8200e-01,  1.6572e+00,  1.1335e+00],\n",
      "        [-6.2700e-01,  3.1068e-02,  3.0630e-01,  1.0545e+00, -5.5582e-01],\n",
      "        [ 1.1317e+00, -2.4191e+00,  6.6356e-01, -7.4405e-01, -4.9677e-01],\n",
      "        [-2.1644e+00, -7.3547e-01, -2.4698e-01, -2.7772e-03, -1.7245e-01],\n",
      "        [ 2.1444e-02, -6.1393e-01,  9.1599e-01, -1.2035e-01, -1.2752e+00],\n",
      "        [-6.7044e-01, -2.1644e+00,  8.0746e-01, -9.0264e-01,  7.2460e-02],\n",
      "        [ 2.8516e-01,  1.5575e+00, -2.1955e+00,  6.6615e-01, -1.9837e-01],\n",
      "        [-1.1044e-01, -5.6244e-01, -4.0386e-01,  1.5119e+00, -7.7897e-01],\n",
      "        [-1.9045e-01, -2.7714e-01,  2.3149e+00,  1.4367e+00, -5.7195e-01],\n",
      "        [ 6.5415e-01, -2.8262e-01,  1.9466e+00, -2.4387e-03,  6.5057e-01],\n",
      "        [ 5.8803e-01, -6.2582e-01, -1.3530e+00,  1.2747e+00,  8.3622e-01],\n",
      "        [-7.1403e-01, -1.3704e+00, -8.9610e-01, -1.9385e-01, -1.2771e+00],\n",
      "        [-1.6170e-01, -1.3204e+00, -1.0461e+00,  1.1395e+00, -5.0475e-01],\n",
      "        [ 1.5720e-01,  6.5730e-01, -9.1842e-01,  2.5598e-01,  1.3683e+00],\n",
      "        [-1.0133e+00,  6.0256e-01, -6.0689e-01, -1.0548e+00,  1.7097e+00],\n",
      "        [-2.0581e-01,  2.1812e-01,  8.7000e-02, -2.8012e-01, -7.8936e-01],\n",
      "        [ 1.3765e+00,  2.0243e+00, -1.1927e-01, -1.6524e-01, -6.7301e-01],\n",
      "        [-1.4192e+00,  1.8404e+00,  9.2786e-01, -8.8967e-02, -5.5135e-01],\n",
      "        [-8.8854e-01,  5.5657e-01,  6.8168e-01, -9.5060e-01,  8.8787e-01],\n",
      "        [-6.8780e-01, -1.9333e+00, -2.7527e-01,  1.1164e+00, -1.3221e-01],\n",
      "        [ 1.1331e+00, -4.1143e-01,  1.5367e+00, -1.1371e+00, -8.1972e-01],\n",
      "        [ 2.0640e-01,  1.9210e-02,  6.4106e-01,  5.8513e-01, -5.8493e-01],\n",
      "        [-1.0934e+00,  1.2526e-01, -1.4964e-01, -1.0364e+00,  1.1886e-01],\n",
      "        [ 1.5444e+00,  4.8854e-01, -8.3411e-01,  6.8364e-01, -9.0427e-01],\n",
      "        [ 7.1639e-01,  6.6983e-01, -2.2044e-01, -2.1072e-01,  3.6288e-01],\n",
      "        [-1.6301e+00,  1.0567e+00,  4.9428e-01, -2.1171e+00,  1.2458e+00],\n",
      "        [-7.6570e-01, -3.4659e-02, -7.2463e-01, -1.4086e+00,  3.6391e-01],\n",
      "        [-1.9467e+00, -1.0381e+00,  5.6039e-01, -1.6255e+00,  5.3446e-01],\n",
      "        [ 1.3520e-02, -1.1858e+00,  9.5676e-01,  2.1713e+00,  1.2418e+00],\n",
      "        [-2.9745e-01,  8.2740e-01, -3.3963e-04, -4.8203e-02,  1.2077e-01],\n",
      "        [ 1.8804e+00, -1.2840e+00,  1.4982e+00, -8.6715e-01, -2.8807e+00],\n",
      "        [ 1.5265e+00, -1.2901e+00,  5.8033e-02, -2.1759e+00, -7.0767e-01],\n",
      "        [-1.6038e+00,  1.7184e+00, -6.6151e-01, -9.4205e-01, -8.0610e-01],\n",
      "        [-8.6153e-01,  7.6099e-01, -1.1874e+00, -2.0596e-01,  6.7245e-01],\n",
      "        [ 8.5850e-01,  2.5547e-01, -7.3003e-01,  8.4283e-01, -3.5837e-01]],\n",
      "       device='cuda:0')\n",
      "features1\n",
      " tensor([[-0.6024, -0.1351,  0.6136, -0.0103,  0.4921],\n",
      "        [ 0.3382, -0.4381, -0.7494,  0.2942, -0.2132],\n",
      "        [ 0.2363,  0.8510, -0.0683,  0.2900, -0.3622],\n",
      "        [ 0.9202, -0.3160, -0.2055, -0.0993, -0.0367],\n",
      "        [-0.5167, -0.0201,  0.3982,  0.6786, -0.3370],\n",
      "        [-0.2612,  0.8750, -0.3356,  0.1915,  0.1299],\n",
      "        [-0.5347, -0.2374, -0.3942, -0.6101, -0.3607],\n",
      "        [-0.3756, -0.3065,  0.0328, -0.5395, -0.6877],\n",
      "        [-0.3709, -0.0833,  0.4312, -0.3808, -0.7243],\n",
      "        [ 0.2716, -0.5855,  0.2562, -0.5934, -0.4070],\n",
      "        [-0.5852, -0.5415, -0.5501,  0.2245, -0.1063],\n",
      "        [-0.5577,  0.0840,  0.4143, -0.4983,  0.5119],\n",
      "        [ 0.3303, -0.3799,  0.5898,  0.1012, -0.6233],\n",
      "        [-0.2526,  0.2729,  0.1853, -0.5224, -0.7446],\n",
      "        [ 0.7868,  0.1772, -0.1323, -0.4625,  0.3437],\n",
      "        [ 0.0303,  0.7797, -0.2837, -0.4354,  0.3480],\n",
      "        [-0.7236,  0.3681, -0.2127,  0.1802, -0.5130],\n",
      "        [-0.9424, -0.1504, -0.0907,  0.1980,  0.2045],\n",
      "        [ 0.5675, -0.3411, -0.2557,  0.6299, -0.3155],\n",
      "        [-0.1605, -0.5899, -0.0907, -0.5025, -0.6046],\n",
      "        [ 0.7723, -0.2961,  0.3235, -0.4449,  0.1154],\n",
      "        [-0.0574, -0.4852, -0.7210, -0.1668,  0.4623],\n",
      "        [ 0.7052, -0.0975, -0.0355,  0.5883,  0.3819],\n",
      "        [ 0.1506,  0.2102, -0.2078, -0.9029, -0.2733],\n",
      "        [ 0.7897,  0.4320,  0.3645,  0.1388, -0.1940],\n",
      "        [ 0.1707,  0.1393, -0.5414, -0.4054,  0.7028],\n",
      "        [-0.7148,  0.2749, -0.5236,  0.1732, -0.3307],\n",
      "        [ 0.4787, -0.1349, -0.5905,  0.5446, -0.3275],\n",
      "        [-0.7601,  0.0635,  0.4578,  0.4323,  0.1476],\n",
      "        [ 0.8112,  0.4553,  0.0597,  0.3327, -0.1427],\n",
      "        [-0.5575,  0.4797, -0.1583, -0.3026, -0.5851],\n",
      "        [ 0.3429,  0.1982,  0.3357,  0.0724, -0.8516],\n",
      "        [ 0.5281,  0.5135, -0.2265, -0.3532,  0.5305],\n",
      "        [-0.6239,  0.0010, -0.2081,  0.4139,  0.6294],\n",
      "        [-0.1495,  0.7915, -0.1225,  0.0879,  0.5731],\n",
      "        [-0.1805, -0.0575,  0.2796, -0.1450, -0.9300],\n",
      "        [-0.4558, -0.1166,  0.4471,  0.5979, -0.4705],\n",
      "        [ 0.4987,  0.5863, -0.1085,  0.3191,  0.5422],\n",
      "        [-0.0371,  0.5409,  0.8228,  0.0951, -0.1413],\n",
      "        [ 0.0733,  0.6942,  0.4102,  0.3587, -0.4646],\n",
      "        [-0.2810, -0.3829,  0.7792,  0.3086,  0.2685],\n",
      "        [ 0.2733, -0.5252,  0.5882,  0.2034,  0.5120],\n",
      "        [-0.2754,  0.0220,  0.4937,  0.7140, -0.4126],\n",
      "        [-0.5640, -0.3972,  0.6265, -0.3124,  0.1846],\n",
      "        [-0.0241, -0.1919, -0.8548,  0.2809, -0.3911],\n",
      "        [-0.6250,  0.2218,  0.1276, -0.3651, -0.6408],\n",
      "        [-0.1766,  0.0096,  0.4701, -0.8427,  0.1940],\n",
      "        [-0.4179, -0.3869,  0.4412, -0.6933,  0.0192],\n",
      "        [ 0.0414,  0.8391,  0.0965, -0.0980,  0.5247],\n",
      "        [-0.4073,  0.0798,  0.1968, -0.5214, -0.7191],\n",
      "        [ 0.3360,  0.2811, -0.6343,  0.4487,  0.4522],\n",
      "        [-0.0290, -0.4157,  0.5158, -0.5181, -0.5401],\n",
      "        [ 0.7447,  0.3374,  0.5689, -0.0816,  0.0360],\n",
      "        [ 0.7765, -0.5182,  0.2213,  0.2804, -0.0302],\n",
      "        [ 0.0740,  0.8773,  0.0649,  0.3784,  0.2784],\n",
      "        [ 0.3576,  0.1693,  0.8200, -0.4136,  0.0028],\n",
      "        [ 0.1743, -0.8605, -0.0864,  0.4701,  0.0262],\n",
      "        [ 0.3067, -0.4414,  0.0472, -0.7489, -0.3848],\n",
      "        [-0.8122, -0.0807, -0.1691,  0.3180,  0.4519],\n",
      "        [ 0.2675, -0.2237, -0.6279, -0.6495, -0.2495],\n",
      "        [ 0.2021,  0.5397, -0.2559,  0.3355, -0.6999],\n",
      "        [ 0.1901,  0.4793, -0.5703, -0.0888,  0.6332],\n",
      "        [-0.1869,  0.3971,  0.8913,  0.1082, -0.0354],\n",
      "        [ 0.5066, -0.1996,  0.6439, -0.4713, -0.2582]], device='cuda:0')\n",
      "features2\n",
      " tensor([[-6.8577e-01, -5.5741e-01, -4.5418e-01, -3.8992e-02, -1.0591e-01],\n",
      "        [-5.0148e-01,  1.5772e-01, -4.9356e-01,  1.6601e-01,  6.7267e-01],\n",
      "        [-6.2002e-02,  8.2166e-01,  4.3477e-01,  3.3206e-01, -1.4745e-01],\n",
      "        [ 8.0404e-01,  2.0010e-02, -1.8403e-01, -2.6310e-01, -5.0004e-01],\n",
      "        [ 8.4801e-01, -1.1856e-01,  3.5036e-01, -2.9651e-01,  2.3697e-01],\n",
      "        [ 4.1321e-01, -2.6451e-01,  5.5037e-02,  8.2312e-01, -2.8059e-01],\n",
      "        [-2.2140e-01, -4.1376e-03, -6.5307e-01, -5.7256e-01,  4.4344e-01],\n",
      "        [ 8.7565e-02, -5.5227e-01,  1.3587e-01,  5.2023e-02,  8.1619e-01],\n",
      "        [-4.8654e-01,  6.8779e-01, -2.6685e-01,  7.5473e-02,  4.6185e-01],\n",
      "        [ 5.2373e-01, -3.7417e-01, -7.7511e-02,  3.2841e-01,  6.8691e-01],\n",
      "        [-2.3324e-01,  6.8019e-01, -3.4470e-01,  3.5443e-01, -4.8837e-01],\n",
      "        [ 4.0535e-01,  9.9454e-02, -8.8343e-01, -2.0146e-01,  6.9066e-02],\n",
      "        [-2.3002e-01, -3.8340e-01,  4.1743e-01,  7.3185e-01,  3.0041e-01],\n",
      "        [ 5.5533e-01, -4.2827e-01,  6.6851e-01,  1.7066e-01, -1.7933e-01],\n",
      "        [ 1.5766e-01, -7.7114e-01, -2.9482e-01, -7.3194e-02, -5.3686e-01],\n",
      "        [ 4.1918e-01,  6.4452e-02,  7.3328e-01,  5.2358e-01, -9.1162e-02],\n",
      "        [-3.7055e-01, -4.2219e-01, -7.1398e-01, -1.7955e-01, -3.7742e-01],\n",
      "        [ 1.5653e-01, -7.4000e-01, -3.5726e-01, -3.4918e-01, -4.2230e-01],\n",
      "        [ 2.1967e-01, -5.0831e-01, -7.5234e-01,  8.3010e-02,  3.4709e-01],\n",
      "        [ 4.8846e-01, -5.3998e-02, -4.9902e-01,  6.7792e-01,  2.2338e-01],\n",
      "        [-2.2296e-01, -4.6356e-01, -2.6463e-01, -7.3973e-01, -3.4375e-01],\n",
      "        [-1.4508e-01,  5.5359e-01, -6.8043e-01,  4.3522e-01, -1.4171e-01],\n",
      "        [ 2.3709e-01, -5.2977e-01,  3.1060e-01, -6.4696e-01,  3.8483e-01],\n",
      "        [ 7.7605e-01,  2.1412e-02, -3.7981e-02, -2.0950e-01, -5.9326e-01],\n",
      "        [-6.2181e-01, -2.2752e-01,  7.1238e-01,  5.5451e-02, -2.2588e-01],\n",
      "        [ 8.1844e-02, -5.5268e-01,  3.6875e-01,  6.1800e-01,  4.1225e-01],\n",
      "        [-2.6161e-01, -1.0054e-01, -7.8938e-01, -2.3696e-01,  4.9212e-01],\n",
      "        [ 5.3352e-01,  5.3727e-01, -4.9637e-01,  1.2505e-01,  4.0581e-01],\n",
      "        [ 4.3709e-01, -2.5260e-01,  7.2975e-02,  1.6868e-02, -8.5996e-01],\n",
      "        [-3.9494e-01, -2.3943e-01,  2.8527e-01,  6.9318e-01,  4.7414e-01],\n",
      "        [-4.5382e-01,  2.2487e-02,  2.2170e-01,  7.6324e-01, -4.0231e-01],\n",
      "        [ 3.9108e-01, -8.3599e-01,  2.2932e-01, -2.5713e-01, -1.7168e-01],\n",
      "        [-9.3871e-01, -3.1898e-01, -1.0712e-01, -1.2045e-03, -7.4794e-02],\n",
      "        [ 1.2686e-02, -3.6321e-01,  5.4191e-01, -7.1200e-02, -7.5445e-01],\n",
      "        [-2.6085e-01, -8.4210e-01,  3.1416e-01, -3.5119e-01,  2.8192e-02],\n",
      "        [ 1.0203e-01,  5.5729e-01, -7.8560e-01,  2.3836e-01, -7.0982e-02],\n",
      "        [-6.0032e-02, -3.0574e-01, -2.1954e-01,  8.2184e-01, -4.2344e-01],\n",
      "        [-6.7917e-02, -9.8834e-02,  8.2554e-01,  5.1235e-01, -2.0397e-01],\n",
      "        [ 3.0109e-01, -1.3008e-01,  8.9597e-01, -1.1225e-03,  2.9944e-01],\n",
      "        [ 2.6586e-01, -2.8294e-01, -6.1172e-01,  5.7630e-01,  3.7807e-01],\n",
      "        [-3.2391e-01, -6.2166e-01, -4.0650e-01, -8.7936e-02, -5.7935e-01],\n",
      "        [-7.6939e-02, -6.2824e-01, -4.9776e-01,  5.4217e-01, -2.4016e-01],\n",
      "        [ 8.7358e-02,  3.6527e-01, -5.1038e-01,  1.4225e-01,  7.6040e-01],\n",
      "        [-4.2096e-01,  2.5033e-01, -2.5213e-01, -4.3822e-01,  7.1030e-01],\n",
      "        [-2.3024e-01,  2.4401e-01,  9.7326e-02, -3.1337e-01, -8.8305e-01],\n",
      "        [ 5.4047e-01,  7.9478e-01, -4.6829e-02, -6.4878e-02, -2.6424e-01],\n",
      "        [-5.5351e-01,  7.1779e-01,  3.6188e-01, -3.4698e-02, -2.1503e-01],\n",
      "        [-4.9242e-01,  3.0845e-01,  3.7779e-01, -5.2682e-01,  4.9206e-01],\n",
      "        [-2.9194e-01, -8.2063e-01, -1.1684e-01,  4.7385e-01, -5.6120e-02],\n",
      "        [ 4.7132e-01, -1.7114e-01,  6.3921e-01, -4.7299e-01, -3.4098e-01],\n",
      "        [ 1.9345e-01,  1.8004e-02,  6.0081e-01,  5.4840e-01, -5.4821e-01],\n",
      "        [-7.1756e-01,  8.2209e-02, -9.8205e-02, -6.8016e-01,  7.8006e-02],\n",
      "        [ 7.1972e-01,  2.2767e-01, -3.8871e-01,  3.1859e-01, -4.2140e-01],\n",
      "        [ 6.5766e-01,  6.1492e-01, -2.0237e-01, -1.9345e-01,  3.3313e-01],\n",
      "        [-5.1415e-01,  3.3329e-01,  1.5590e-01, -6.6774e-01,  3.9292e-01],\n",
      "        [-4.2610e-01, -1.9287e-02, -4.0324e-01, -7.8387e-01,  2.0251e-01],\n",
      "        [-6.8360e-01, -3.6454e-01,  1.9679e-01, -5.7083e-01,  1.8768e-01],\n",
      "        [ 4.6160e-03, -4.0488e-01,  3.2666e-01,  7.4135e-01,  4.2397e-01],\n",
      "        [-3.3466e-01,  9.3091e-01, -3.8211e-04, -5.4234e-02,  1.3588e-01],\n",
      "        [ 4.6321e-01, -3.1631e-01,  3.6905e-01, -2.1361e-01, -7.0962e-01],\n",
      "        [ 5.0237e-01, -4.2456e-01,  1.9099e-02, -7.1608e-01, -2.3290e-01],\n",
      "        [-5.8564e-01,  6.2746e-01, -2.4155e-01, -3.4399e-01, -2.9435e-01],\n",
      "        [-4.7967e-01,  4.2369e-01, -6.6112e-01, -1.1467e-01,  3.7440e-01],\n",
      "        [ 5.8225e-01,  1.7326e-01, -4.9512e-01,  5.7162e-01, -2.4305e-01]],\n",
      "       device='cuda:0')\n",
      "labels1\n",
      " tensor([[1],\n",
      "        [1],\n",
      "        [4],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [3],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [2],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [2],\n",
      "        [0],\n",
      "        [3],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [2],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [3],\n",
      "        [0],\n",
      "        [2],\n",
      "        [2],\n",
      "        [1],\n",
      "        [1],\n",
      "        [4],\n",
      "        [4],\n",
      "        [0],\n",
      "        [2],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [3],\n",
      "        [3],\n",
      "        [4],\n",
      "        [2],\n",
      "        [0],\n",
      "        [3],\n",
      "        [3],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [2],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [3]], device='cuda:0')\n",
      "labels2\n",
      " tensor([[1],\n",
      "        [2],\n",
      "        [0],\n",
      "        [2],\n",
      "        [0],\n",
      "        [0],\n",
      "        [2],\n",
      "        [2],\n",
      "        [0],\n",
      "        [2],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [2],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [2],\n",
      "        [1],\n",
      "        [2],\n",
      "        [2],\n",
      "        [1],\n",
      "        [2],\n",
      "        [1],\n",
      "        [1],\n",
      "        [2],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [2],\n",
      "        [0],\n",
      "        [0],\n",
      "        [2],\n",
      "        [2],\n",
      "        [0],\n",
      "        [2],\n",
      "        [2],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [2],\n",
      "        [0],\n",
      "        [2],\n",
      "        [1],\n",
      "        [2],\n",
      "        [0],\n",
      "        [0],\n",
      "        [2],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [2],\n",
      "        [0],\n",
      "        [2],\n",
      "        [2],\n",
      "        [0],\n",
      "        [2],\n",
      "        [2],\n",
      "        [1],\n",
      "        [0]], device='cuda:0')\n",
      "mask\n",
      " tensor([[1., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [1., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "mask2\n",
      " tensor([[1., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 1., 0.,  ..., 1., 0., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 1., 0.,  ..., 1., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 1.]], device='cuda:0')\n",
      "mask3\n",
      " tensor([1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1.,\n",
      "        1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0.,\n",
      "        0., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1.,\n",
      "        1., 0., 1., 0., 0., 1., 0., 0., 1., 1.], device='cuda:0')\n",
      "mask4\n",
      " tensor([0., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "        0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 1., 0., 1., 1., 0., 1., 1., 0., 0.], device='cuda:0')\n",
      "anchor_dot_contrast1\n",
      " tensor([[ 0.3158,  0.6147,  0.2346,  ..., -0.0432,  0.0232, -1.6070],\n",
      "        [ 0.7280,  0.0733, -1.1557,  ..., -0.6605,  0.0682,  1.4241],\n",
      "        [-1.1570, -0.2920,  1.6094,  ...,  0.8380,  0.2469,  1.1453],\n",
      "        ...,\n",
      "        [-0.4045,  1.3462,  0.0224,  ...,  0.3424,  1.4724,  0.5428],\n",
      "        [-0.9970, -0.5788,  1.5333,  ...,  0.2332, -0.7138, -0.8214],\n",
      "        [-0.9658, -1.7113, -0.0677,  ..., -0.6786, -1.5923, -0.5305]],\n",
      "       device='cuda:0')\n",
      "anchor_dot_contrast2\n",
      " tensor([[ 1.9997,  0.8045, -1.2210,  ...,  0.4116,  0.7154, -0.5347],\n",
      "        [ 0.8045,  2.0006, -0.1961,  ...,  0.5132,  1.7334, -0.1775],\n",
      "        [-1.2210, -0.1961,  2.0004,  ...,  0.7522, -0.0059,  0.2333],\n",
      "        ...,\n",
      "        [ 0.4116,  0.5132,  0.7522,  ...,  1.9996,  1.2711, -0.4752],\n",
      "        [ 0.7154,  1.7334, -0.0059,  ...,  1.2711,  2.0002, -0.0702],\n",
      "        [-0.5347, -0.1775,  0.2333,  ..., -0.4752, -0.0702,  1.9998]],\n",
      "       device='cuda:0')\n",
      "anchor_dot_contrast3\n",
      " tensor([[ 2.9997,  1.8045, -0.2210,  ...,  1.4116,  1.7154,  0.4653],\n",
      "        [ 1.8045,  3.0006,  0.8039,  ...,  1.5132,  2.7334,  0.8225],\n",
      "        [-0.2210,  0.8039,  3.0004,  ...,  1.7522,  0.9941,  1.2333],\n",
      "        ...,\n",
      "        [ 1.4116,  1.5132,  1.7522,  ...,  2.9996,  2.2711,  0.5248],\n",
      "        [ 1.7154,  2.7334,  0.9941,  ...,  2.2711,  3.0002,  0.9298],\n",
      "        [ 0.4653,  0.8225,  1.2333,  ...,  0.5248,  0.9298,  2.9998]],\n",
      "       device='cuda:0')\n",
      "exp_logits1\n",
      " tensor([[0.3157, 0.4256, 0.2910,  ..., 0.2204, 0.2356, 0.0462],\n",
      "        [0.3913, 0.2033, 0.0595,  ..., 0.0976, 0.2023, 0.7849],\n",
      "        [0.0536, 0.1274, 0.8528,  ..., 0.3943, 0.2183, 0.5362],\n",
      "        ...,\n",
      "        [0.0995, 0.5731, 0.1525,  ..., 0.2100, 0.6501, 0.2566],\n",
      "        [0.0788, 0.1197, 0.9896,  ..., 0.2697, 0.1046, 0.0939],\n",
      "        [0.0520, 0.0247, 0.1275,  ..., 0.0692, 0.0278, 0.0803]],\n",
      "       device='cuda:0')\n",
      "exp_logits2\n",
      " tensor([[1.0000, 0.3027, 0.0399,  ..., 0.2043, 0.2769, 0.0793],\n",
      "        [0.3024, 1.0000, 0.1112,  ..., 0.2259, 0.7655, 0.1133],\n",
      "        [0.0399, 0.1112, 1.0000,  ..., 0.2870, 0.1345, 0.1708],\n",
      "        ...,\n",
      "        [0.2043, 0.2262, 0.2872,  ..., 1.0000, 0.4826, 0.0842],\n",
      "        [0.2767, 0.7659, 0.1345,  ..., 0.4823, 1.0000, 0.1261],\n",
      "        [0.0793, 0.1133, 0.1709,  ..., 0.0842, 0.1262, 1.0000]],\n",
      "       device='cuda:0')\n",
      "exp_logits3\n",
      " tensor([[2.7183, 0.8227, 0.1085,  ..., 0.5554, 0.7526, 0.2156],\n",
      "        [0.8219, 2.7183, 0.3022,  ..., 0.6142, 2.0808, 0.3079],\n",
      "        [0.1085, 0.3022, 2.7183,  ..., 0.7801, 0.3656, 0.4643],\n",
      "        ...,\n",
      "        [0.5554, 0.6148, 0.7808,  ..., 2.7183, 1.3118, 0.2288],\n",
      "        [0.7522, 2.0818, 0.3657,  ..., 1.3112, 2.7183, 0.3429],\n",
      "        [0.2156, 0.3081, 0.4646,  ..., 0.2288, 0.3430, 2.7183]],\n",
      "       device='cuda:0')\n",
      "logits_mask1\n",
      " tensor([[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        ...,\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.]], device='cuda:0')\n",
      "logits_mask2\n",
      " tensor([[0., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 0., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 0.,  ..., 1., 1., 1.],\n",
      "        ...,\n",
      "        [1., 1., 1.,  ..., 0., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 0., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 0.]], device='cuda:0')\n",
      "positives_mask1\n",
      " tensor([[1., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [1., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "negatives_mask1\n",
      " tensor([[0., 1., 1.,  ..., 1., 0., 1.],\n",
      "        [0., 1., 1.,  ..., 1., 0., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        ...,\n",
      "        [0., 1., 1.,  ..., 1., 0., 1.],\n",
      "        [0., 1., 1.,  ..., 1., 0., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.]], device='cuda:0')\n",
      "positives_mask2\n",
      " tensor([[0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "negatives_mask2\n",
      " tensor([[0., 1., 1.,  ..., 1., 0., 1.],\n",
      "        [1., 0., 1.,  ..., 0., 1., 1.],\n",
      "        [1., 1., 0.,  ..., 1., 1., 0.],\n",
      "        ...,\n",
      "        [1., 0., 1.,  ..., 0., 1., 1.],\n",
      "        [0., 1., 1.,  ..., 1., 0., 1.],\n",
      "        [1., 1., 0.,  ..., 1., 1., 0.]], device='cuda:0')\n",
      "num_positives_per_row\n",
      " tensor([14., 14.,  0., 25., 25., 25., 25., 14., 14., 25., 25., 25.,  0., 25.,\n",
      "        14., 25., 25., 25., 25., 14., 25., 14., 14., 25., 25.,  0., 25., 25.,\n",
      "        25., 14., 14., 25., 25., 14., 25.,  0., 25., 25., 25., 14., 14.,  0.,\n",
      "         0., 25., 25., 25., 14., 25.,  0.,  0.,  0., 25., 25.,  0.,  0., 14.,\n",
      "        14., 14., 25., 25., 14., 14., 14.,  0.], device='cuda:0')\n",
      "num_positives_per_row_selected\n",
      " tensor([14.,  0.,  0.,  0., 25., 25.,  0.,  0., 14.,  0., 25., 25.,  0., 25.,\n",
      "        14.,  0., 25., 25., 25.,  0., 25.,  0.,  0., 25.,  0.,  0., 25.,  0.,\n",
      "        25., 14., 14., 25.,  0., 14., 25.,  0.,  0., 25.,  0.,  0., 14.,  0.,\n",
      "         0.,  0., 25.,  0., 14.,  0.,  0.,  0.,  0., 25., 25.,  0.,  0.,  0.,\n",
      "        14.,  0.,  0., 25.,  0.,  0., 14.,  0.], device='cuda:0')\n",
      "num_positives_per_row_unselected\n",
      " tensor([ 0., 14.,  0., 25.,  0.,  0., 25., 14.,  0., 25.,  0.,  0.,  0.,  0.,\n",
      "         0., 25.,  0.,  0.,  0., 14.,  0., 14., 14.,  0., 25.,  0.,  0., 25.,\n",
      "         0.,  0.,  0.,  0., 25.,  0.,  0.,  0., 25.,  0., 25., 14.,  0.,  0.,\n",
      "         0., 25.,  0., 25.,  0., 25.,  0.,  0.,  0.,  0.,  0.,  0.,  0., 14.,\n",
      "         0., 14., 25.,  0., 14., 14.,  0.,  0.], device='cuda:0')\n",
      "shape!!!!!!!!!!!!!!!!!!\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 64])\n",
      "denominator\n",
      " tensor([[13.0352],\n",
      "        [12.6828],\n",
      "        [10.0883],\n",
      "        [12.3077],\n",
      "        [10.8748],\n",
      "        [13.2041],\n",
      "        [12.9949],\n",
      "        [11.4094],\n",
      "        [12.1831],\n",
      "        [11.8250],\n",
      "        [11.3100],\n",
      "        [12.4936],\n",
      "        [12.5857],\n",
      "        [12.9368],\n",
      "        [13.8042],\n",
      "        [11.8459],\n",
      "        [13.0864],\n",
      "        [13.5391],\n",
      "        [12.9640],\n",
      "        [12.9619],\n",
      "        [12.6127],\n",
      "        [12.3306],\n",
      "        [11.1407],\n",
      "        [12.4774],\n",
      "        [10.9670],\n",
      "        [12.8684],\n",
      "        [13.3610],\n",
      "        [11.9796],\n",
      "        [13.1735],\n",
      "        [11.8495],\n",
      "        [11.5194],\n",
      "        [13.2240],\n",
      "        [12.0232],\n",
      "        [12.5187],\n",
      "        [12.3724],\n",
      "        [12.7079],\n",
      "        [12.9353],\n",
      "        [12.0473],\n",
      "        [10.7624],\n",
      "        [13.1461],\n",
      "        [13.2643],\n",
      "        [13.4919],\n",
      "        [12.3333],\n",
      "        [12.5412],\n",
      "        [10.6104],\n",
      "        [10.6759],\n",
      "        [10.3828],\n",
      "        [10.7842],\n",
      "        [13.3089],\n",
      "        [11.7298],\n",
      "        [12.3217],\n",
      "        [12.4077],\n",
      "        [12.5663],\n",
      "        [10.6563],\n",
      "        [11.5289],\n",
      "        [12.7451],\n",
      "        [11.9676],\n",
      "        [12.7472],\n",
      "        [11.1932],\n",
      "        [13.1732],\n",
      "        [12.1675],\n",
      "        [11.4490],\n",
      "        [13.3204],\n",
      "        [12.8366]], device='cuda:0')\n",
      "denominator1\n",
      " tensor([[35.4334],\n",
      "        [34.4755],\n",
      "        [27.4230],\n",
      "        [33.4559],\n",
      "        [29.5607],\n",
      "        [35.8925],\n",
      "        [35.3238],\n",
      "        [31.0140],\n",
      "        [33.1171],\n",
      "        [32.1438],\n",
      "        [30.7436],\n",
      "        [33.9611],\n",
      "        [34.2114],\n",
      "        [35.1660],\n",
      "        [37.5237],\n",
      "        [32.2005],\n",
      "        [35.5726],\n",
      "        [36.8031],\n",
      "        [35.2398],\n",
      "        [35.2342],\n",
      "        [34.2850],\n",
      "        [33.5180],\n",
      "        [30.2835],\n",
      "        [33.9172],\n",
      "        [29.8114],\n",
      "        [34.9800],\n",
      "        [36.3188],\n",
      "        [32.5641],\n",
      "        [35.8092],\n",
      "        [32.2103],\n",
      "        [31.3129],\n",
      "        [35.9466],\n",
      "        [32.6823],\n",
      "        [34.0295],\n",
      "        [33.6318],\n",
      "        [34.5437],\n",
      "        [35.1617],\n",
      "        [32.7481],\n",
      "        [29.2552],\n",
      "        [35.7347],\n",
      "        [36.0561],\n",
      "        [36.6749],\n",
      "        [33.5254],\n",
      "        [34.0906],\n",
      "        [28.8419],\n",
      "        [29.0201],\n",
      "        [28.2233],\n",
      "        [29.3144],\n",
      "        [36.1774],\n",
      "        [31.8848],\n",
      "        [33.4938],\n",
      "        [33.7276],\n",
      "        [34.1588],\n",
      "        [28.9669],\n",
      "        [31.3387],\n",
      "        [34.6446],\n",
      "        [32.5314],\n",
      "        [34.6504],\n",
      "        [30.4263],\n",
      "        [35.8085],\n",
      "        [33.0747],\n",
      "        [31.1217],\n",
      "        [36.2086],\n",
      "        [34.8934]], device='cuda:0')\n",
      "log_probs\n",
      " tensor([[-3.7207, -3.4219, -3.8019,  ..., -4.0797, -4.0133, -5.6435],\n",
      "        [-3.4785, -4.1332, -5.3623,  ..., -4.8671, -4.1384, -2.7824],\n",
      "        [-5.2370, -4.3720, -2.4706,  ..., -3.2420, -3.8331, -2.9347],\n",
      "        ...,\n",
      "        [-4.7454, -2.9946, -4.3185,  ..., -3.9985, -2.8685, -3.7981],\n",
      "        [-5.1300, -4.7119, -2.5998,  ..., -3.8999, -4.8469, -4.9544],\n",
      "        [-5.5096, -6.2551, -4.6116,  ..., -5.2225, -6.1362, -5.0743]],\n",
      "       device='cuda:0')\n",
      "log_probs1\n",
      " tensor([[-4.7207, -4.4219, -4.8019,  ..., -5.0797, -5.0133, -6.6435],\n",
      "        [-4.4785, -5.1332, -6.3623,  ..., -5.8671, -5.1384, -3.7824],\n",
      "        [-6.2370, -5.3720, -3.4706,  ..., -4.2420, -4.8331, -3.9347],\n",
      "        ...,\n",
      "        [-5.7454, -3.9946, -5.3185,  ..., -4.9985, -3.8685, -4.7981],\n",
      "        [-6.1300, -5.7119, -3.5998,  ..., -4.8999, -5.8469, -5.9544],\n",
      "        [-6.5096, -7.2551, -5.6116,  ..., -6.2225, -7.1362, -6.0743]],\n",
      "       device='cuda:0')\n",
      "log_probs_\n",
      " tensor([-4.0846, -4.2224, -4.7151, -3.9170, -4.1745, -4.8110, -4.5639, -4.5831,\n",
      "        -4.2647, -4.5724, -3.9894, -4.3531, -3.9970, -4.1975, -4.2587, -4.5275,\n",
      "        -3.9712, -4.5426, -4.3523, -4.7508, -4.0280, -4.4315, -3.9503, -3.8668,\n",
      "        -4.5587, -4.2027, -4.2550, -4.0672, -4.3598], device='cuda:0')\n",
      "log_probs1_\n",
      " tensor([-5.0789, -4.8878, -5.4241, -4.6678, -5.0834, -5.4525, -4.9384, -5.1756,\n",
      "        -5.5771, -4.9344, -5.0402, -5.6554, -5.2874, -5.1792, -5.6366, -5.3449,\n",
      "        -5.2614, -5.2985, -5.5024, -5.2454, -4.9416, -5.2280, -5.5040],\n",
      "       device='cuda:0')\n",
      "loss\n",
      " tensor([4.0846, 4.2224, 4.7151, 3.9170, 4.1745, 4.8110, 4.5639, 4.5831, 4.2647,\n",
      "        4.5724, 3.9894, 4.3531, 3.9970, 4.1975, 4.2587, 4.5275, 3.9712, 4.5426,\n",
      "        4.3523, 4.7508, 4.0280, 4.4315, 3.9503, 3.8668, 4.5587, 4.2027, 4.2550,\n",
      "        4.0672, 4.3598], device='cuda:0')\n",
      "loss1\n",
      " tensor([5.0789, 4.8878, 5.4241, 4.6678, 5.0834, 5.4525, 4.9384, 5.1756, 5.5771,\n",
      "        4.9344, 5.0402, 5.6554, 5.2874, 5.1792, 5.6366, 5.3449, 5.2614, 5.2985,\n",
      "        5.5024, 5.2454, 4.9416, 5.2280, 5.5040], device='cuda:0')\n",
      "loss\n",
      " tensor(4.2955, device='cuda:0')\n",
      "loss1\n",
      " tensor(5.2324, device='cuda:0')\n",
      "tensor(9.5279, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "num_features = 5\n",
    "features1 = torch.randn(batch_size, num_features).cuda()\n",
    "features2 = torch.randn(batch_size, num_features).cuda()\n",
    "labels1 = torch.randint(0, 3, (batch_size, num_features)).cuda()\n",
    "labels2 = torch.randint(0, 3, (batch_size,)).cuda()\n",
    "worstk = [0, 1]\n",
    "tmask = None\n",
    "\n",
    "loss_function = SupConLoss3()\n",
    "loss = loss_function(tmask, worstk, features1, features2, labels1, labels2)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positives_mask1: tensor([[1, 1, 1, 0, 1],\n",
      "        [1, 0, 0, 0, 1],\n",
      "        [1, 0, 1, 0, 0],\n",
      "        [1, 1, 0, 1, 0],\n",
      "        [1, 1, 0, 0, 0]])\n",
      "num_positives_per_row: tensor([4, 2, 2, 3, 2])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 5\n",
    "num_features = 3\n",
    "\n",
    "# 随机生成一个形状为 (batch_size, batch_size) 的整数张量，范围在 [0, 1]\n",
    "positives_mask1 = torch.randint(0, 2, (batch_size, batch_size))\n",
    "\n",
    "print(\"positives_mask1:\", positives_mask1)\n",
    "\n",
    "num_positives_per_row = torch.sum(positives_mask1, axis=1)\n",
    "\n",
    "print(\"num_positives_per_row:\", num_positives_per_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SupConLoss(nn.Module):\n",
    "   \n",
    "    def __init__(self, temperature=0.07, contrast_mode='all',\n",
    "                 base_temperature=0.07):\n",
    "        super(SupConLoss, self).__init__()\n",
    "        self.temperature = temperature\n",
    "        self.contrast_mode = contrast_mode\n",
    "        self.base_temperature = base_temperature\n",
    "\n",
    "    def forward(self, features, labels=None, mask=None):\n",
    "     \n",
    "        device = (torch.device('cuda')\n",
    "                  if features.is_cuda\n",
    "                  else torch.device('cpu'))\n",
    "\n",
    "        if len(features.shape) < 3:\n",
    "            raise ValueError('`features` needs to be [bsz, n_views, ...],'\n",
    "                             'at least 3 dimensions are required')\n",
    "        if len(features.shape) > 3:\n",
    "            features = features.view(features.shape[0], features.shape[1], -1)\n",
    "\n",
    "        batch_size = features.shape[0]\n",
    "        if labels is not None and mask is not None:\n",
    "            raise ValueError('Cannot define both `labels` and `mask`')\n",
    "        elif labels is None and mask is None:\n",
    "            mask = torch.eye(batch_size, dtype=torch.float32).to(device)\n",
    "        elif labels is not None:\n",
    "            labels = labels.contiguous().view(-1, 1)\n",
    "            if labels.shape[0] != batch_size:\n",
    "                raise ValueError('Num of labels does not match num of features')\n",
    "            mask = torch.eq(labels, labels.T).float().to(device)\n",
    "        else:\n",
    "            mask = mask.float().to(device)\n",
    "        print('labels\\n',labels)\n",
    "        print('mask!!!!!!\\n',mask)\n",
    "        contrast_count = features.shape[1]\n",
    "        contrast_feature = torch.cat(torch.unbind(features, dim=1), dim=0)\n",
    "        if self.contrast_mode == 'one':\n",
    "            anchor_feature = features[:, 0]\n",
    "            anchor_count = 1\n",
    "        elif self.contrast_mode == 'all':\n",
    "            anchor_feature = contrast_feature\n",
    "            anchor_count = contrast_count\n",
    "        else:\n",
    "            raise ValueError('Unknown mode: {}'.format(self.contrast_mode))\n",
    "\n",
    "        # compute logits\n",
    "        anchor_dot_contrast = torch.div(\n",
    "            torch.matmul(anchor_feature, contrast_feature.T),\n",
    "            self.temperature)\n",
    "        # for numerical stability\n",
    "        logits_max, _ = torch.max(anchor_dot_contrast, dim=1, keepdim=True)\n",
    "        logits = anchor_dot_contrast - logits_max.detach()\n",
    "        print('anchor_dot_contrast.shape\\n',anchor_dot_contrast.shape)\n",
    "        print('logits_max.shape\\n',logits_max.shape)\n",
    "        print('logits.shape\\n',logits.shape)\n",
    "        # tile mask\n",
    "        mask = mask.repeat(anchor_count, contrast_count)\n",
    "        # mask-out self-contrast cases\n",
    "        logits_mask = torch.scatter(\n",
    "            torch.ones_like(mask),\n",
    "            1,\n",
    "            torch.arange(batch_size * anchor_count).view(-1, 1).to(device),\n",
    "            0\n",
    "        )\n",
    "        mask = mask * logits_mask\n",
    "\n",
    "        # compute log_prob\n",
    "        exp_logits = torch.exp(logits) * logits_mask\n",
    "        log_prob = logits - torch.log(exp_logits.sum(1, keepdim=True))\n",
    "        print('logits shape\\n',logits.shape)\n",
    "        print('exp_logits.shape\\n',exp_logits.shape)\n",
    "        print('log_prob.shape\\n',log_prob.shape)\n",
    "\n",
    "        # compute mean of log-likelihood over positive\n",
    "        # modified to handle edge cases when there is no positive pair\n",
    "        # for an anchor point. \n",
    "        # Edge case e.g.:- \n",
    "        # features of shape: [4,1,...]\n",
    "        # labels:            [0,1,1,2]\n",
    "        # loss before mean:  [nan, ..., ..., nan] \n",
    "        #mask_pos_pairs = mask.sum(1)\n",
    "        #mask_pos_pairs = torch.where(mask_pos_pairs < 1e-6, 1, mask_pos_pairs)\n",
    "        #mask_pos_pairs = mask.sum(1)\n",
    "        mask_pos_pairs = mask.sum(1)\n",
    "        mask_pos_pairs = mask_pos_pairs.type(torch.LongTensor)\n",
    "        mask_pos_pairs = torch.where(mask_pos_pairs < 0, 1, mask_pos_pairs)\n",
    "        mask_pos_pairs = mask_pos_pairs.to(device)\n",
    "        mean_log_prob_pos = (mask * log_prob).sum(1) / mask_pos_pairs\n",
    "        #mask_pos_pairs = torch.where(mask_pos_pairs < torch.tensor(1e-6, dtype=mask_pos_pairs.dtype), 1, mask_pos_pairs)\n",
    "        mean_log_prob_pos = (mask * log_prob).sum(1) / mask_pos_pairs\n",
    "\n",
    "        # loss\n",
    "        loss = - (self.temperature / self.base_temperature) * mean_log_prob_pos\n",
    "        loss = loss.view(anchor_count, batch_size).mean()\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels\n",
      " tensor([[0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [2]], device='cuda:0')\n",
      "mask!!!!!!\n",
      " tensor([[1., 1., 0., 0.],\n",
      "        [1., 1., 0., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1.]], device='cuda:0')\n",
      "anchor_dot_contrast.shape\n",
      " torch.Size([8, 8])\n",
      "logits_max.shape\n",
      " torch.Size([8, 1])\n",
      "logits.shape\n",
      " torch.Size([8, 8])\n",
      "logits shape\n",
      " torch.Size([8, 8])\n",
      "exp_logits.shape\n",
      " torch.Size([8, 8])\n",
      "log_prob.shape\n",
      " torch.Size([8, 8])\n",
      "tensor(10.9031, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 创建随机特征向量和标签\n",
    "batch_size = 4\n",
    "n_views = 2\n",
    "num_features = 3\n",
    "features = torch.randn(batch_size, n_views, num_features).cuda()\n",
    "labels = torch.randint(0, 3, (batch_size,)).cuda()\n",
    "\n",
    "# 创建损失函数实例\n",
    "loss_function = SupConLoss().cuda()\n",
    "\n",
    "# 计算损失\n",
    "loss = loss_function(features, labels)\n",
    "print(loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch1.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
